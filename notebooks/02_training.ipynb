{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c42887",
   "metadata": {},
   "source": [
    "# 02 – Model Training\n",
    "\n",
    "In this notebook, we train the MLPClassifier model using the PyTorch training loop defined in `train.py`.\n",
    "\n",
    "We will:\n",
    "- Load preprocessed data\n",
    "- Create datasets and dataloaders\n",
    "- Instantiate the model\n",
    "- Define loss function and optimizer\n",
    "- Train the model for 20 epochs\n",
    "- Save the best model based on validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1ec727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from src.model import MLPClassifier\n",
    "from src.train import train_model\n",
    "from src.data_loader import HumanActivityDataset\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✅ Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e5bc2",
   "metadata": {},
   "source": [
    "## Load processed data\n",
    "\n",
    "We load the preprocessed NumPy arrays saved at the end of the `01_exploration.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16557e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/processed_data.pkl\", \"rb\") as f:\n",
    "    X_train_final, y_train_final, X_val, y_val, X_test_scaled, y_test_encoded = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe76c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = HumanActivityDataset(X_train_final, y_train_final)\n",
    "val_dataset = HumanActivityDataset(X_val, y_val)\n",
    "test_dataset = HumanActivityDataset(X_test_scaled, y_test_encoded)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2558d22",
   "metadata": {},
   "source": [
    "## Define MLP architecture\n",
    "\n",
    "We will use:\n",
    "- 561 input features\n",
    "- Two hidden layers: 256 and 128 neurons\n",
    "- ReLU activation\n",
    "- Dropout (0.3)\n",
    "- Output layer with 6 classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86236984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=561, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "    input_dim=561,\n",
    "    hidden_dims=[256, 128],\n",
    "    output_dim=6,\n",
    "    dropout_rate=0.3\n",
    ").to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41c051",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer\n",
    "\n",
    "We use:\n",
    "- CrossEntropyLoss (for multi-class classification)\n",
    "- Adam optimizer with learning rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56972f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ac6ee",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We will train for 20 epochs and save the best model based on validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0a94250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Adam' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# ✅ esta ordem é importante!\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../outputs/best_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/human-activity-recognation/src/train.py:72\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, device, epochs, save_path)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     train_loss, train_acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     val_loss, val_acc = validate(model, val_loader, criterion, device)\n\u001b[32m     75\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m].append(train_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/human-activity-recognation/src/train.py:31\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, criterion, optimizer, device)\u001b[39m\n\u001b[32m     29\u001b[39m optimizer.zero_grad()\n\u001b[32m     30\u001b[39m outputs = model(inputs)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m loss.backward()\n\u001b[32m     33\u001b[39m optimizer.step()\n",
      "\u001b[31mTypeError\u001b[39m: 'Adam' object is not callable"
     ]
    }
   ],
   "source": [
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,         # ✅ esta ordem é importante!\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    epochs=20,\n",
    "    save_path=\"../outputs/best_model.pth\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
